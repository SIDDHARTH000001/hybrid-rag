llm:
  # provider: "gcp"
  # model_name: "gemini-2.5-flash" 
  # api_key: "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"  
  # temperature: 0.1
  # max_tokens: 2048
  provider: "azure"
  model_name: "xxxxxxxxxxxxxxxxxxx"
  api_key: "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
  endpoint : "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
  version : "2025-01-01-preview"
  temperature: 0.1
  max_tokens: 2048

embeddings:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"  
  device: "cpu" 
  batch_size: 32

hybrid_search:
  bm25_weight: 0.65
  semantic_weight: 0.35
  top_k: 3

document_processing:
  chunk_size: 500  
  chunk_overlap: 100  
  min_chunk_size: 50  

vector_store:
  faiss_index_path: "./data/faiss_index"
  metadata_path: "./data/metadata.pkl"

server:
  host: "localhost"
  port: 8002
  upload_dir: "./uploads"
  max_file_size_mb: 50
